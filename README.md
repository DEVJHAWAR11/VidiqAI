# Klypse â€” YouTube Video Intelligence Engine

> Ask any question about any YouTube video. Get AI-powered answers streamed in real time.

[![Python](https://img.shields.io/badge/Python-3.10+-blue)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green)](https://fastapi.tiangolo.com)
[![LangChain](https://img.shields.io/badge/LangChain-RAG-orange)](https://langchain.com)
[![Docker](https://img.shields.io/badge/Docker-ready-blue)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

> ğŸŒ **Live Demo:** [klypse-ai-youtube-extension-bot.netlify.app](https://klypse-ai-youtube-extension-bot.netlify.app/)

---

## What is Klypse?

Klypse is a **Chrome extension + FastAPI backend** that lets you ask questions about any YouTube video and get AI-powered answers in real time. It handles videos with no subtitles, non-English content, and works offline via a local Whisper fallback.

---

## Architecture

```
Chrome Extension (JavaScript)
        â”‚  POST { video_id, question }
        â–¼
FastAPI Backend  /ask/stream
        â”‚
        â”œâ”€ FAISS store exists? â”€YESâ”€â–º RetrievalQA (MMR, k=3) â”€â–º SSE Word Stream
        â”‚
       NO
        â–¼
Transcript Pipeline (4-tier fallback)
  â‘  YouTubeTranscriptApi  â€” tries 10 languages (en, hi, es, fr, de, ru, ar, bn, id)
  â‘¡ Groq Whisper API      â€” downloads audio via yt-dlp, transcribes (files < 24MB)
  â‘¢ Local Whisper Model   â€” fully offline, any file size
        â–¼
  clean_text() â†’ chunk_text(size=500) â†’ FAISS Vector Store (per-video, disk-persisted)
        â–¼
  LangChain RetrievalQA â†’ Groq LLaMA-3.3-70b â†’ SSE Stream â†’ Chrome Extension
```

---

## Tech Stack

| Layer | Technology |
|---|---|
| Backend API | FastAPI + Python 3.10 |
| LLM | Groq API (LLaMA-3.3-70b-versatile) |
| Orchestration | LangChain RetrievalQA |
| Retrieval | FAISS + MMR (per-video, disk-persisted) |
| Transcription | YouTubeTranscriptApi + Groq Whisper + Local Whisper |
| Audio Download | yt-dlp + ffmpeg |
| Frontend | Chrome Extension (JavaScript) + Netlify Landing Page |
| Containerization | Docker + docker-compose |
| Cloud | AWS EC2 (with documented IP restriction workaround) |

---

## Key Engineering Decisions

### 1. Per-video FAISS Index
Each video gets its own FAISS index at `./data/faiss/{video_id}/` â€” zero cross-video context contamination, instant load on repeated queries, survives server restarts.

### 2. 4-Tier Transcript Fallback
- **Tier 1:** Official subtitles via YouTubeTranscriptApi (10 languages)
- **Tier 2:** Groq Whisper API â€” cloud transcription for audio < 24MB
- **Tier 3:** Local Whisper model â€” fully offline, any file size
- Works on virtually any video that has audio

### 3. MMR Retrieval
Uses Maximum Marginal Relevance instead of plain similarity search â€” retrieves chunks that are both **relevant** and **diverse**, preventing redundant context from similar transcript segments.

### 4. AWS IP Restriction â€” Diagnosed & Documented
YouTube blocks requests from AWS cloud IPs. Issue was diagnosed via yt-dlp verbose logs (HTTP 403 from AWS-origin), confirmed by comparing EC2 vs local curl responses, resolved via local-fallback strategy, and proven via live demo on the landing page.

### 5. SSE Streaming with Deduplication
Answers stream word-by-word via `StreamingResponse` with `text/event-stream`. Post-processing deduplication handles repetition artifacts from streamed LLM outputs.

---

## Project Structure

```
VidiqAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints.py     # /check and /ask/stream (SSE streaming)
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py          # API key dependency
â”‚   â”‚   â”‚   â””â”€â”€ deps.py          # LLM initialization
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ transcripts.py   # 4-tier transcript pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ qa_chain.py      # LangChain RetrievalQA + MMR + custom prompt
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py    # Embedding model config
â”‚   â”‚   â”‚   â””â”€â”€ processing.py    # Text cleaning + chunking
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py  # FAISS create/load
â”‚   â”‚   â”‚   â””â”€â”€ cache.py         # Transcript disk cache
â”‚   â”‚   â”œâ”€â”€ config.py        # Pydantic settings (env-based)
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app + CORS
â”‚   â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â””â”€â”€ chrome-extension/        # JS frontend (injects into YouTube pages)
```

---

## Setup & Run

```bash
# 1. Clone
git clone https://github.com/DEVJHAWAR11/VidiqAI.git
cd VidiqAI/backend

# 2. Configure environment
cp .env.example .env
# Add your GROQ_API_KEY to .env

# 3. Run with Docker
docker-compose up --build

# Backend: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

**Chrome Extension:**
1. Chrome â†’ `chrome://extensions/` â†’ Enable Developer Mode
2. Load unpacked â†’ select `chrome-extension/` folder
3. Open any YouTube video and use the extension

---

## API Reference

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/` | API info + version |
| `GET` | `/health` | Service health check |
| `GET` | `/check/{video_id}` | Check transcript/vectorstore availability |
| `POST` | `/ask/stream` | Stream AI answer via SSE |

**Request body for `/ask/stream`:**
```json
{
  "video_id": "dQw4w9WgXcQ",
  "question": "What is the main topic of this video?"
}
```

---

## Known Constraints

| Constraint | Details |
|---|---|
| AWS IP blocking | YouTube blocks requests from AWS-hosted servers. Full diagnosis documented; working demo on [landing page](https://klypse-ai-youtube-extension-bot.netlify.app/). |
| Groq Whisper limit | Audio files > 24MB fall back to local Whisper automatically. |
| Local Whisper speed | Base model ~30â€“60s for long videos on CPU. |

---

## Author

**Dev Jhawar** â€” [GitHub](https://github.com/DEVJHAWAR11) | KIIT University, CSE (CGPA: 9.66)
